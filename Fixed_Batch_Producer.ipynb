{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import confluent_kafka\n",
    "import time\n",
    "from pykafka import KafkaClient\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import timezone, datetime\n",
    "#%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'kafkatestkafkatestkafkatestkafkatestkafkatestkafkatestkafkatestkafkatestkafkatestkafkatestkafkatestk'\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "msg_count = 18000\n",
    "msg_size = 100\n",
    "msg_payload = ('kafkatest' * 20).encode()[:msg_size]\n",
    "print(msg_payload)\n",
    "print(len(msg_payload))\n",
    "topic = 'confluent-kafka-topic'\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "producer_timings = {}\n",
    "producer_messages={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confluent_kafka_producer_performance():\n",
    "    \n",
    "    topic = 'confluent-kafka-topic'\n",
    "    conf = {'bootstrap.servers': bootstrap_servers,'compression.codec': 'lz4','default.topic.config': {'acks': 0}}\n",
    "    producer = confluent_kafka.Producer(**conf)\n",
    "    messages_to_retry = 0\n",
    "\n",
    "    #producer_start = time.time()\n",
    "    for i in range(msg_count):\n",
    "        try:\n",
    "            producer.produce(topic, value=msg_payload)      \n",
    "        except BufferError as e:\n",
    "            messages_to_retry += 1\n",
    "\n",
    "    # hacky retry messages that over filled the local buffer\n",
    "    for i in range(messages_to_retry):\n",
    "        producer.poll(0)\n",
    "        try:\n",
    "            producer.produce(topic, value=msg_payload)\n",
    "        except BufferError as e:\n",
    "            producer.poll(0)\n",
    "            producer.produce(topic, value=msg_payload)\n",
    "\n",
    "    producer.flush()\n",
    "            \n",
    "    #return time.time() - producer_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 6192000  in  67.197084 s\n",
      "average write per second is : 103200.0\n"
     ]
    }
   ],
   "source": [
    "total_docs=0\n",
    "j=0\n",
    "itr=0\n",
    "MAX_ITR=60\n",
    "startf = datetime.now();\n",
    "write_readings={}\n",
    "\n",
    "while itr<MAX_ITR: \n",
    "    start = datetime.now();\n",
    "    for index in range(100000000000):\n",
    "        try:\n",
    "           \n",
    "            confluent_kafka_producer_performance()\n",
    "            \n",
    "            timec=int((datetime.now() - start).total_seconds())\n",
    "\n",
    "            if timec==1:\n",
    "                j=j+1\n",
    "                itr=itr+1\n",
    "                write_readings[j]=index*msg_count\n",
    "                total_docs=total_docs + index*msg_count\n",
    "                break\n",
    "        except:\n",
    "            print ('Unexpected error:', sys.exc_info()[0], ', for index ', index)\n",
    "            raise\n",
    "#consumer.close()            \n",
    "print ('Write',total_docs, ' in ', (datetime.now() - startf).total_seconds(), 's')\n",
    "print ('average write per second is :',total_docs/MAX_ITR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,162000)\n",
      "(2,144000)\n",
      "(3,108000)\n",
      "(4,144000)\n",
      "(5,90000)\n",
      "(6,108000)\n",
      "(7,72000)\n",
      "(8,108000)\n",
      "(9,126000)\n",
      "(10,126000)\n",
      "(11,126000)\n",
      "(12,108000)\n",
      "(13,54000)\n",
      "(14,126000)\n",
      "(15,108000)\n",
      "(16,90000)\n",
      "(17,90000)\n",
      "(18,54000)\n",
      "(19,108000)\n",
      "(20,90000)\n",
      "(21,108000)\n",
      "(22,108000)\n",
      "(23,108000)\n",
      "(24,108000)\n",
      "(25,126000)\n",
      "(26,90000)\n",
      "(27,108000)\n",
      "(28,108000)\n",
      "(29,108000)\n",
      "(30,144000)\n",
      "(31,90000)\n",
      "(32,108000)\n",
      "(33,90000)\n",
      "(34,126000)\n",
      "(35,72000)\n",
      "(36,108000)\n",
      "(37,108000)\n",
      "(38,126000)\n",
      "(39,108000)\n",
      "(40,108000)\n",
      "(41,108000)\n",
      "(42,90000)\n",
      "(43,90000)\n",
      "(44,108000)\n",
      "(45,72000)\n",
      "(46,90000)\n",
      "(47,72000)\n",
      "(48,90000)\n",
      "(49,108000)\n",
      "(50,90000)\n",
      "(51,108000)\n",
      "(52,144000)\n",
      "(53,72000)\n",
      "(54,90000)\n",
      "(55,90000)\n",
      "(56,72000)\n",
      "(57,126000)\n",
      "(58,90000)\n",
      "(59,108000)\n",
      "(60,72000)\n"
     ]
    }
   ],
   "source": [
    "for i in write_readings:\n",
    "    print('(',i,',',write_readings[i],')',sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_df = pd.DataFrame.from_dict(write_readings, orient='index').rename(columns={0: 'time_in_seconds'})\n",
    "consumer_df.sort_index(inplace=True)\n",
    "consumer_df\n",
    "\n",
    "consumer_df.plot(kind='bar', subplots=True, figsize=(10, 10), title=\"Producer Fixed Batch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
